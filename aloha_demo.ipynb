{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8240b7f",
   "metadata": {},
   "source": [
    "# LeRobot ALOHA Environment Demo\n",
    "\n",
    "This notebook demonstrates the gym-aloha environment from LeRobot. ALOHA (A Low-cost Open-source Hardware System for Bimanual Teleoperation) is a bimanual manipulation environment with tasks like insertion and cube transfer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6213c9",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006805b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib pandas seaborn scikit-learn\n",
    "!pip install IPython\n",
    "# Install gym-aloha environment\n",
    "!pip install 'lerobot[aloha]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3330840e",
   "metadata": {},
   "source": [
    "**Note:** After running the installation cell above, you may need to restart the kernel if you get compatibility errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529fd850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca0615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gym_aloha to register the environment\n",
    "import gym_aloha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29be146c",
   "metadata": {},
   "source": [
    "## Available ALOHA Tasks\n",
    "\n",
    "The gym-aloha environment provides several tasks:\n",
    "- **AlohaInsertion-v0**: Insert a peg into a socket\n",
    "- **AlohaTransferCube-v0**: Transfer a cube from one location to another\n",
    "\n",
    "These tasks involve bimanual manipulation with a simulated ALOHA robot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_env",
   "metadata": {},
   "source": [
    "## Create the ALOHA Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment - Try AlohaInsertion-v0 first\n",
    "task = \"AlohaInsertion-v0\"  # or \"AlohaTransferCube-v0\"\n",
    "env = gym.make(f'gym_aloha/{task}', render_mode='rgb_array')\n",
    "\n",
    "print(f\"Task: {task}\")\n",
    "print(f\"Observation space: {env.observation_space}\")\n",
    "print(f\"Action space: {env.action_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb995058",
   "metadata": {},
   "source": [
    "## Reset Environment and Visualize Initial State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the environment\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Render and display the initial state\n",
    "frame = env.render()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(frame)\n",
    "plt.title(f\"Initial State of {task}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Display observation information\n",
    "if isinstance(observation, dict):\n",
    "    print(\"\\nObservation keys:\")\n",
    "    for key, value in observation.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            print(f\"  {key}: shape {value.shape}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {type(value)}\")\n",
    "else:\n",
    "    print(f\"\\nObservation shape: {observation.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ead4b7",
   "metadata": {},
   "source": [
    "## Run Random Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8adccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a few steps with random actions\n",
    "num_steps = 100\n",
    "total_reward = 0\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # Sample a random action\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # Step the environment\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    \n",
    "    # Break if episode ends\n",
    "    if terminated or truncated:\n",
    "        print(f\"Episode ended at step {step + 1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nTotal steps: {step + 1}\")\n",
    "print(f\"Total reward: {total_reward:.4f}\")\n",
    "print(f\"Terminated: {terminated}, Truncated: {truncated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f5cb5a",
   "metadata": {},
   "source": [
    "## Visualize Episode with Random Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0cbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect frames for visualization\n",
    "frames = []\n",
    "rewards = []\n",
    "num_steps = 100\n",
    "\n",
    "observation, info = env.reset(seed=123)\n",
    "frames.append(env.render())\n",
    "\n",
    "for step in range(num_steps):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    frames.append(env.render())\n",
    "    rewards.append(reward)\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "print(f\"Collected {len(frames)} frames\")\n",
    "print(f\"Total reward: {sum(rewards):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9482beef",
   "metadata": {},
   "source": [
    "## Display Selected Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 6 frames evenly spaced throughout the episode\n",
    "num_display = 6\n",
    "indices = np.linspace(0, len(frames) - 1, num_display, dtype=int)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    axes[i].imshow(frames[idx])\n",
    "    axes[i].set_title(f\"Step {idx}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cdddce",
   "metadata": {},
   "source": [
    "## Plot Reward Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rewards\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(rewards, label='Reward per step')\n",
    "plt.plot(np.cumsum(rewards), label='Cumulative reward', linestyle='--')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Rewards During Episode')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average reward per step: {np.mean(rewards):.4f}\")\n",
    "print(f\"Max reward: {np.max(rewards):.4f}\")\n",
    "print(f\"Min reward: {np.min(rewards):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6680fa84",
   "metadata": {},
   "source": [
    "## Explore Action and Observation Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0705c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample and visualize some actions\n",
    "print(\"Sample actions from the action space:\")\n",
    "for i in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    print(f\"Action {i+1}: shape={action.shape}, values={action}\")\n",
    "\n",
    "print(f\"\\nAction space bounds:\")\n",
    "print(f\"Low: {env.action_space.low}\")\n",
    "print(f\"High: {env.action_space.high}\")\n",
    "print(f\"\\nAction space represents control for both arms of the ALOHA robot.\")\n",
    "print(f\"Typically includes joint positions/velocities for all 14 joints (7 per arm).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "try_different_task",
   "metadata": {},
   "source": [
    "## Try Different Task (Optional)\n",
    "\n",
    "You can easily switch between different ALOHA tasks by changing the task name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different_task",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close current environment\n",
    "env.close()\n",
    "\n",
    "# Try a different task\n",
    "task = \"AlohaTransferCube-v0\"  # Switch to cube transfer task\n",
    "env = gym.make(f'gym_aloha/{task}', render_mode='rgb_array')\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "frame = env.render()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(frame)\n",
    "plt.title(f\"Initial State of {task}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Switched to: {task}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830edf43",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d94e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the environment\n",
    "env.close()\n",
    "print(\"Environment closed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30619e28",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've explored the ALOHA environment, you can:\n",
    "\n",
    "1. **Train a policy** - Use LeRobot's ACT (Action Chunking Transformer) policy, which was specifically designed for ALOHA\n",
    "2. **Load demonstrations** - Load pre-recorded expert demonstrations from Hugging Face:\n",
    "   - `lerobot/aloha_sim_insertion_human`\n",
    "   - `lerobot/aloha_sim_insertion_scripted`\n",
    "   - `lerobot/aloha_sim_transfer_cube_human`\n",
    "   - `lerobot/aloha_sim_transfer_cube_scripted`\n",
    "3. **Collect your own data** - Record demonstrations for imitation learning\n",
    "4. **Evaluate policies** - Test trained ACT models on the environment\n",
    "5. **Bimanual manipulation** - Explore coordinated control of both robot arms\n",
    "\n",
    "### Example: Loading a dataset\n",
    "\n",
    "```python\n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset\n",
    "\n",
    "dataset = LeRobotDataset(\"lerobot/aloha_sim_insertion_human\")\n",
    "print(f\"Dataset has {len(dataset)} frames\")\n",
    "```\n",
    "\n",
    "### Example: Training ACT policy\n",
    "\n",
    "```bash\n",
    "python lerobot/scripts/train.py \\\n",
    "    policy=act \\\n",
    "    env=aloha \\\n",
    "    env.task=AlohaInsertion-v0 \\\n",
    "    dataset_repo_id=lerobot/aloha_sim_insertion_human\n",
    "```\n",
    "\n",
    "Check out the [LeRobot documentation](https://github.com/huggingface/lerobot) for more examples!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
